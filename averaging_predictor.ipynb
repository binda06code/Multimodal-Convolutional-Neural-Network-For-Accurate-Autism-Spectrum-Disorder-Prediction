{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea443e66",
   "metadata": {},
   "source": [
    "The function does predictions on all images in a specified directory (sdir) and prints out the results.  \n",
    "It has two modes of operation. In the non_averaging mode a seperate prediction is made for each image   \n",
    "and the predicted class and probability is printed out for each image.  \n",
    "In the averaging mode a prediction is made on each image and the probabilities are stored.  \n",
    "When the predictions for all images are completed the probabilites are summed for each class.    \n",
    "The class having the highest probability sum is then select as the predicted class for all images.  \n",
    "The predicted class and its averaged probability is printed out  \n",
    "Lets say you have 10 images of the face of the same child and you want to get a prediction if the child is autistic.    \n",
    "You can get 10 individual prediction and look at each prediction. However you will get a much higher confidence    \n",
    "prediction using the predictor in the averaging mode for the 10 images. Of course you can just predict on one image of a childs face  \n",
    "but you get a much higher confidence if you use multiple facial images of the child and use the predictor in the averaging mode.\n",
    "  \n",
    " The parameters in the function are:   \n",
    "  * model_path is the  full path to the trained model \n",
    "  * txt_path is the full path to the classes.txt file generated by the autism.ipynb notebook when it is run to produce the trained model.    \n",
    "      The classes.txt file is of the form class0, class1, ...classN. For the case of the autistic dataset the file appears as  \n",
    "      autistic,non_autistic.\n",
    "  * img_size is a tupple (height, width) representing the image shape used to train the model   \n",
    "  * mode is a string. If mode=='ave' the predictor provides a single prediction of the class and class probability. If mode is any    \n",
    "      other string value the predictor provides an individual prediction for each image and returns a dataframe with columns  \n",
    "      filename, class, probability. Each row of the dataframe contain the image file name, the class predicted and the probability    \n",
    "      of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7eba86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TI\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5de19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(sdir, model_path, txt_path, img_size,  mode):\n",
    "    with open(txt_path, 'r') as f:\n",
    "        content=f.read() \n",
    "    split=content.split(',')\n",
    "    classes=[split[i] for i in range(len(split))]\n",
    "    num_classes=len(classes) \n",
    "    print(\"Loading the model. This may take several seconds\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print ('model is loaded')\n",
    "    flist=sorted(os.listdir(sdir))\n",
    "    print ('predicting the class of the ', len(flist), ' files in ', sdir)   \n",
    "    filepaths=[]       \n",
    "    sum_list=[0 for i in range( num_classes )]    \n",
    "    for i, f in enumerate(flist):\n",
    "        fpath=os.path.join(sdir,f)\n",
    "        filepaths.append(fpath)\n",
    "    Fseries=pd.Series(filepaths, name ='filepaths')\n",
    "    df=pd.concat([Fseries], axis=1)\n",
    "    gen=tf.keras.preprocessing.image.ImageDataGenerator().flow_from_dataframe(df, x_col='filepaths', y_col=None, target_size=img_size, class_mode=None, shuffle=False)\n",
    "    preds=model.predict(gen)\n",
    "    cclass=[] # list of predicted classes\n",
    "    pclass=[] # list of class probabilities   \n",
    "    for i, p in enumerate(preds):   #iterate through the predictions     \n",
    "        for  j, cp in enumerate(p): # update the sum_list by adding in the probabilities of each class\n",
    "            sum_list[j] +=cp        \n",
    "        index=np.argmax(p) # find the index of the value in p that has the highest probability\n",
    "        klass=classes[index] # get the class with the highest probability\n",
    "        cclass.append(klass)\n",
    "        pclass.append(p[index]* 100)\n",
    "    Pseries=pd.Series(pclass, name='% Probability')\n",
    "    Cseries=pd.Series(cclass, name='Predicted Class')\n",
    "    Fseries=pd.Series(flist, name='Filename')                                                                          \n",
    "    pdf=pd.concat([Fseries, Cseries, Pseries], axis=1)  # dataframe of the form Filename, Predicted Class, % Probability      \n",
    "    ave_index=np.argmax(sum_list)\n",
    "    ave_class=classes[ave_index]    \n",
    "    ave_p=sum_list[ave_index]* 100/len(flist)    \n",
    "    if mode == 'ave':\n",
    "        print (f'The class prediction for all images is {ave_class} with a probability of {ave_p:6.2f} %')\n",
    "        return ave_class, ave_p                                             \n",
    "    else:\n",
    "        print (pdf)\n",
    "        return pdf                                                                   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823f2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model. This may take several seconds\n",
      "model is loaded\n",
      "predicting the class of the  5  files in  C:\\Users\\TI\\Documents\\fyp\\DataSets\\image dataset of autism\\tests_non_autistic\n",
      "Found 5 validated image filenames.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "  Filename Predicted Class  % Probability\n",
      "0  006.jpg    non_autistic      63.518983\n",
      "1  007.jpg    non_autistic      99.965513\n",
      "2  008.jpg    non_autistic      72.807181\n",
      "3  009.jpg        autistic      99.854940\n",
      "4  010.jpg    non_autistic      99.998379\n"
     ]
    }
   ],
   "source": [
    "# example in non averaging mode-individual predicts ae made and a dataframe is returned\n",
    "txt_path=r\"C:\\Users\\TI\\Documents\\fyp\\DataSets\\image dataset of autism\\classes.txt\"\n",
    "sdir=r\"C:\\Users\\TI\\Documents\\fyp\\DataSets\\image dataset of autism\\tests_non_autistic\"\n",
    "img_size=(200,200)\n",
    "mode=''\n",
    "#model_path=r\"C:\\Temp\\Autism\\autism-vgg19_77.0.h5\"\n",
    "model_path=r\"C:\\Temp\\Autism\\autism-B3_84.5.h5\"\n",
    "df= predictor(sdir, model_path, txt_path, img_size, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a652c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model. This may take several seconds\n",
      "model is loaded\n",
      "predicting the class of the  5  files in  C:\\Users\\TI\\Documents\\fyp\\DataSets\\image dataset of autism\\tests_non_autistic\n",
      "Found 5 validated image filenames.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "The class prediction for all images is non_autistic with a probability of  67.29 %\n"
     ]
    }
   ],
   "source": [
    "# example on same data of averaging mode - 1 prediction is made for all images. returns the predicted class and its probability\n",
    "mode='ave'\n",
    "ave_class, ave_p  =predictor(sdir, model_path, txt_path, img_size,  mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55404f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
